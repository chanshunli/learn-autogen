## https://gist.github.com/mberman84/ea207e7d9e5f8c5f6a3252883ef16df3

# 1. # create new .py file with code found below
# 2. # install ollama
# 3. # install model you want “ollama run mistral”
# 4. conda create -n autogen python=3.11
# 5. conda activate autogen
# 6. which python
# 7. python -m pip install pyautogen
# 7. ollama run mistral
# 8. ollama run codellama
# 9. # open new terminal
# 10. conda activate autogen
# 11. python -m pip install litellm
# 12. litellm --model ollama/mistral
# 13. # open new terminal
# 14. conda activate autogen
# 15. litellm --model ollama/codellama

### Code used:
import autogen

#config_list_mistral = [
#    {
#        'base_url': "http://0.0.0.0:8000",
#        'api_key': "NULL"
#    }
#]

## 多模型配合：一个做plan，另外一个做codeing。
config_list_mistral = [
  {
    "model": "llama3.1",
    "base_url": "http://localhost:11434/v1",
    "api_key": "ollama",
  }
]

#config_list_codellama = [
#    {
#        'base_url': "http://0.0.0.0:25257",
#        'api_key': "NULL"
#    }
#]

config_list_codellama = [
  {
    "model": "codellama",
    "base_url": "http://localhost:11434/v1",
    "api_key": "ollama",
  }
]

llm_config_mistral={
    "config_list": config_list_mistral,
}

llm_config_codellama={
    "config_list": config_list_codellama,
}

coder = autogen.AssistantAgent(
    name="Coder",
    llm_config=llm_config_codellama
)

user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    human_input_mode="NEVER",
    max_consecutive_auto_reply=10,
    is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
    code_execution_config={"work_dir": "web"},
    llm_config=llm_config_mistral,
    system_message="""Reply TERMINATE if the task has been solved at full satisfaction.
Otherwise, reply CONTINUE, or the reason why the task is not solved yet."""
)

task="""
Write a python script to output numbers 1 to 100 and then the user_proxy agent should run the script
"""

user_proxy.initiate_chat(coder, message=task)


## ----------- 跑起来了，效果不错👍 -------------- 谷歌搜索 autogen 使用ollama ！
# (emacspy) 坚持去λ化(中-易) jim-emacs-fun-py  master @ prunp autogen/autogen_chat_codellama_py.py
# user_proxy (to Coder):
#
#
# Write a python script to output numbers 1 to 100 and then the user_proxy agent should run the script
#
#
# --------------------------------------------------------------------------------
# Coder (to user_proxy):
#
# ```
# filename: countdown.py
# #!/usr/bin/env python3
#
# count = 100 # set count to 100
# while count > 0: # while loop counts from 100 to 1
#    print(count); # print the count variable
#    count -= 1; # decrements the counter by one
#
# # User Proxy code will go here!
# ```
#
# --------------------------------------------------------------------------------
#
# >>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...
# user_proxy (to Coder):
#
# exitcode: 1 (execution failed)
# Code output:
# Traceback (most recent call last):
#   File "", line 1, in <module>
#     filename: countdown.py
#               ^^^^^^^^^
# NameError: name 'countdown' is not defined
#
#
# --------------------------------------------------------------------------------
# Coder (to user_proxy):
#
#  The error indicates that the `filename` parameter is undefined. This is because the value of the `filename` variable is not passed to the script correctly. Here are possible solutions:
# * Use a different parameter name, such as `file_name`, instead of `filename`.
# * Ensure that the correct file path and name are specified in the `filename` parameter when executing the script.
# * Make sure the file exists and is accessible by the user running the script.
#
# --------------------------------------------------------------------------------
#
# [autogen.oai.client: 08-03 09:44:22] {329} WARNING - Model llama3.1 is not found. The cost will be 0. In your config_list, add field {"price" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.
# user_proxy (to Coder):
#
# In this case, none of those solutions apply because we don't need to pass a specific filename as an argument to the script. The error message can be ignored.
#
# To fix the issue, we simply remove the line that sets `filename`:
#
# ```
# # countdown.py
# count = 100 # set count to 100
# while count > 0: # while loop counts from 100 to 1
#    print(count); # print the count variable
#    count -= 1; # decrements the counter by one
#
# # User Proxy code will go here!
# ```
#
# The script will then execute without any issues.
#
# --------------------------------------------------------------------------------
# [autogen.oai.client: 08-03 09:44:36] {329} WARNING - Model codellama is not found. The cost will be 0. In your config_list, add field {"price" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.
# Coder (to user_proxy):
#
#  We suggest you remove the line that sets `filename`:
# ```
# # countdown.py
# count = 100 # set count to 100
# while count > 0: # while loop counts from 100 to 1
#    print(count); # print the count variable
#    count -= 1; # decrements the counter by one
#
# # User Proxy code will go here!
# ```
# The script will then execute without any issues.
#
# --------------------------------------------------------------------------------
#
# >>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...
# user_proxy (to Coder):
#
# exitcode: 0 (execution succeeded)
# Code output:
# 100# 99# 98# 97# 96# 95# 94# 93# 92# 91# 90# 89# 88# 87# 86# 85# 84# 83# 82# 81# 80# 79# 78# 77# 76# 75# 74# 73# 72# 71# 70# 69# 68# 67# 66# 65# 64# 63# 62# 61# 60# 59# 58# 57# 56# 55# 54# 53# 52# 51# 50# 49# 48# 47# 46# 45# 44# 43# 42# 41# 40# 39# 38# 37# 36# 35# 34# 33# 32# 31# 30# 29# 28# 27# 26# 25# 24# 23# 22# 21# 20# 19# 18# 17# 16# 15# 14# 13# 12# 11# 10# 9# 8# 7# 6# 5# 4# 3# 2# 1# #
# --------------------------------------------------------------------------------
# [autogen.oai.client: 08-03 09:44:44] {329} WARNING - Model codellama is not found. The cost will be 0. In your config_list, add field {"price" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.
# Coder (to user_proxy):
#
#  We suggest you remove the line that sets `filename`:
# ```
# # countdown.py
# count = 100 # set count to 100
# while count > 0: # while loop counts from 100 to 1
#    print(count); # print the count variable
#    count -= 1; # decrements the counter by one
#
# # User Proxy code will go here!
# ```
# The script will then execute without any issues and output numbers 1 to 100.
#
# --------------------------------------------------------------------------------
#
# >>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...
# user_proxy (to Coder):
#
# exitcode: 0 (execution succeeded)
# Code output:
# 100# 99# 98# 97# 96# 95# 94# 93# 92# 91# 90# 89# 88# 87# 86# 85# 84# 83# 82# 81# 80# 79# 78# 77# 76# 75# 74# 73# 72# 71# 70# 69# 68# 67# 66# 65# 64# 63# 62# 61# 60# 59# 58# 57# 56# 55# 54# 53# 52# 51# 50# 49# 48# 47# 46# 45# 44# 43# 42# 41# 40# 39# 38# 37# 36# 35# 34# 33# 32# 31# 30# 29# 28# 27# 26# 25# 24# 23# 22# 21# 20# 19# 18# 17# 16# 15# 14# 13# 12# 11# 10# 9# 8# 7# 6# 5# 4# 3# 2# 1#
#
# --------------------------------------------------------------------------------
# [autogen.oai.client: 08-03 09:44:52] {329} WARNING - Model codellama is not found. The cost will be 0. In your config_list, add field {"price" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.
# Coder (to user_proxy):
#
#  We suggest you remove the line that sets `filename`:
# ```
# # countdown.py
# count = 100 # set count to 100
# while count > 0: # while loop counts from 100 to 1
#    print(count); # print the count variable
#    count -= 1; # decrements the counter by one
#
# # User Proxy code will go here!
# ```
# The script will then execute without any issues and output numbers 1 to 100.
#
# --------------------------------------------------------------------------------
#
# >>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...
# user_proxy (to Coder):
#
# exitcode: 0 (execution succeeded)
# Code output:
# 100# 99# 98# 97# 96# 95# 94# 93# 92# 91# 90# 89# 88# 87# 86# 85# 84# 83# 82# 81# 80# 79# 78# 77# 76# 75# 74# 73# 72# 71# 70# 69# 68# 67# 66# 65# 64# 63# 62# 61# 60# 59# 58# 57# 56# 55# 54# 53# 52# 51# 50# 49# 48# 47# 46# 45# 44# 43# 42# 41# 40# 39# 38# 37# 36# 35# 34# 33# 32# 31# 30# 29# 28# 27# 26# 25# 24# 23# 22# 21# 20# 19# 18# 17# 16# 15# 14# 13# 12# 11# 10# 9# 8# 7# 6# 5# 4# 3# 2# 1#
#
# --------------------------------------------------------------------------------
# [autogen.oai.client: 08-03 09:45:07] {329} WARNING - Model codellama is not found. The cost will be 0. In your config_list, add field {"price" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.
# Coder (to user_proxy):
#
#  We suggest you remove the line that sets `filename`:
# ```
# # countdown.py
# count = 100 # set count to 100
# while count > 0: # while loop counts from 100 to 1
#    print(count); # print the count variable
#    count -= 1; # decrements the counter by one
#
# # User Proxy code will go here!
# ```
# The script will then execute without any issues and output numbers 1 to 100.
#
# --------------------------------------------------------------------------------
#
# >>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...
# user_proxy (to Coder):
#
# exitcode: 0 (execution succeeded)
# Code output:
# 100# 99# 98# 97# 96# 95# 94# 93# 92# 91# 90# 89# 88# 87# 86# 85# 84# 83# 82# 81# 80# 79# 78# 77# 76# 75# 74# 73# 72# 71# 70# 69# 68# 67# 66# 65# 64# 63# 62# 61# 60# 59# 58# 57# 56# 55# 54# 53# 52# 51# 50# 49# 48# 47# 46# 45# 44# 43# 42# 41# 40# 39# 38# 37# 36# 35# 34# 33# 32# 31# 30# 29# 28# 27# 26# 25# 24# 23# 22# 21# 20# 19# 18# 17# 16# 15# 14# 13# 12# 11# 10# 9# 8# 7# 6# 5# 4# 3# 2# 1#
#
# --------------------------------------------------------------------------------
# [autogen.oai.client: 08-03 09:45:24] {329} WARNING - Model codellama is not found. The cost will be 0. In your config_list, add field {"price" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.
# Coder (to user_proxy):
#
#  We suggest you remove the line that sets `filename`:
# ```
# # countdown.py
# count = 100 # set count to 100
# while count > 0: # while loop counts from 100 to 1
#    print(count); # print the count variable
#    count -= 1; # decrements the counter by one
#
# # User Proxy code will go here!
# ```
# The script will then execute without any issues and output numbers 1 to 100
#
# --------------------------------------------------------------------------------
#
# >>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...
# user_proxy (to Coder):
#
# exitcode: 0 (execution succeeded)
# Code output:
# 100# 99# 98# 97# 96# 95# 94# 93# 92# 91# 90# 89# 88# 87# 86# 85# 84# 83# 82# 81# 80# 79# 78# 77# 76# 75# 74# 73# 72# 71# 70# 69# 68# 67# 66# 65# 64# 63# 62# 61# 60# 59# 58# 57# 56# 55# 54# 53# 52# 51# 50# 49# 48# 47# 46# 45# 44# 43# 42# 41# 40# 39# 38# 37# 36# 35# 34# 33# 32# 31# 30# 29# 28# 27# 26# 25# 24# 23# 22# 21# 20# 19# 18# 17# 16# 15# 14# 13# 12# 11# 10# 9# 8# 7# 6# 5# 4# 3# 2# 1#
#
# --------------------------------------------------------------------------------
# [autogen.oai.client: 08-03 09:45:33] {329} WARNING - Model codellama is not found. The cost will be 0. In your config_list, add field {"price" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.
# Coder (to user_proxy):
#
#  We suggest you remove the line that sets `filename`:
# ```
# # countdown.py
# count = 100 # set count to 100
# while count > 0: # while loop counts from 100 to 1
#    print(count); # print the count variable
#    count -= 1; # decrements the counter by one
#
# # User Proxy code will go here!
# ```
# The script will then execute without any issues and output numbers 1 to 100.
#
# --------------------------------------------------------------------------------
#
# >>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...
# user_proxy (to Coder):
#
# exitcode: 0 (execution succeeded)
# Code output:
# 100# 99# 98# 97# 96# 95# 94# 93# 92# 91# 90# 89# 88# 87# 86# 85# 84# 83# 82# 81# 80# 79# 78# 77# 76# 75# 74# 73# 72# 71# 70# 69# 68# 67# 66# 65# 64# 63# 62# 61# 60# 59# 58# 57# 56# 55# 54# 53# 52# 51# 50# 49# 48# 47# 46# 45# 44# 43# 42# 41# 40# 39# 38# 37# 36# 35# 34# 33# 32# 31# 30# 29# 28# 27# 26# 25# 24# 23# 22# 21# 20# 19# 18# 17# 16# 15# 14# 13# 12# 11# 10# 9# 8# 7# 6# 5# 4# 3# 2# 1##
# --------------------------------------------------------------------------------
# [autogen.oai.client: 08-03 09:45:44] {329} WARNING - Model codellama is not found. The cost will be 0. In your config_list, add field {"price" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.
# Coder (to user_proxy):
#
#  We suggest you remove the line that sets `filename`:
# ```
# # countdown.py
# count = 100 # set count to 100
# while count > 0: # while loop counts from 100 to 1
#    print(count); # print the count variable
#    count -= 1; # decrements the counter by one
#
# # User Proxy code will go here!
# ```
# The script will then execute without any issues and output numbers 1 to 100.
#
# --------------------------------------------------------------------------------
#
# >>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...
# user_proxy (to Coder):
#
# exitcode: 0 (execution succeeded)
# Code output:
# 100# 99# 98# 97# 96# 95# 94# 93# 92# 91# 90# 89# 88# 87# 86# 85# 84# 83# 82# 81# 80# 79# 78# 77# 76# 75# 74# 73# 72# 71# 70# 69# 68# 67# 66# 65# 64# 63# 62# 61# 60# 59# 58# 57# 56# 55# 54# 53# 52# 51# 50# 49# 48# 47# 46# 45# 44# 43# 42# 41# 40# 39# 38# 37# 36# 35# 34# 33# 32# 31# 30# 29# 28# 27# 26# 25# 24# 23# 22# 21# 20# 19# 18# 17# 16# 15# 14# 13# 12# 11# 10# 9# 8# 7# 6# 5# 4# 3# 2# 1##
# --------------------------------------------------------------------------------
# [autogen.oai.client: 08-03 09:45:58] {329} WARNING - Model codellama is not found. The cost will be 0. In your config_list, add field {"price" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.
# Coder (to user_proxy):
#
#  We suggest you remove the line that sets `filename`:
# ```
# # countdown.py
# count = 100 # set count to 100
# while count > 0: # while loop counts from 100 to 1
#    print(count); # print the count variable
#    count -= 1; # decrements the counter by one
#
# # User Proxy code will go here!
# ```
# The script will then execute without any issues and output numbers 1 to 100
#
# --------------------------------------------------------------------------------
#
# >>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...
# user_proxy (to Coder):
#
# exitcode: 0 (execution succeeded)
# Code output:
# 100# 99# 98# 97# 96# 95# 94# 93# 92# 91# 90# 89# 88# 87# 86# 85# 84# 83# 82# 81# 80# 79# 78# 77# 76# 75# 74# 73# 72# 71# 70# 69# 68# 67# 66# 65# 64# 63# 62# 61# 60# 59# 58# 57# 56# 55# 54# 53# 52# 51# 50# 49# 48# 47# 46# 45# 44# 43# 42# 41# 40# 39# 38# 37# 36# 35# 34# 33# 32# 31# 30# 29# 28# 27# 26# 25# 24# 23# 22# 21# 20# 19# 18# 17# 16# 15# 14# 13# 12# 11# 10# 9# 8# 7# 6# 5# 4# 3# 2# 1#
#
# --------------------------------------------------------------------------------
# [autogen.oai.client: 08-03 09:46:12] {329} WARNING - Model codellama is not found. The cost will be 0. In your config_list, add field {"price" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.
# Coder (to user_proxy):
#
#  We suggest you remove the line that sets `filename`:
# ```
# # countdown.py
# count = 100 # set count to 100
# while count > 0: # while loop counts from 100 to 1
#    print(count); # print the count variable
#    count -= 1; # decrements the counter by one
#
# # User Proxy code will go here!
# ```
# The script will then execute without any issues and output numbers 1 to 100.
#
# --------------------------------------------------------------------------------
# (emacspy) 坚持去λ化(中-易) jim-emacs-fun-py  master @
#
